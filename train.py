import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# ==== 1. Settings ====
BATCH_SIZE = 32
EPOCHS = 5
NUM_CLASSES = 7   # 7 benthic species
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… Using device: {DEVICE}")

# ==== 2. Data Transforms ====
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

# ==== 3. Load Dataset ====
data_dir = 'classification_dataset/images'
full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])

# Split dataset: 80% train / 20% validation
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])
val_dataset.dataset.transform = data_transforms['val']

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

class_names = full_dataset.classes
print(f"ðŸ“Š Classes: {class_names}")

# ==== 4. Load Pretrained ResNet-50 ====
model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)

# Freeze feature extractor layers
for param in model.parameters():
    param.requires_grad = False

# Replace final layer with our 7-class output
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, NUM_CLASSES)
model = model.to(DEVICE)

# ==== 5. Loss & Optimizer ====
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=0.001)

# ==== 6. Training ====
for epoch in range(EPOCHS):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)
    epoch_loss = running_loss / len(train_loader.dataset)
    print(f"ðŸ“† Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss:.4f}")

# ==== 7. Evaluation ====
model.eval()
all_preds = []
all_labels = []
with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

print("\nðŸ“ˆ Classification Report:\n")
print(classification_report(all_labels, all_preds, target_names=class_names))

# ==== 8. Confusion Matrix ====
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8,6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=45)
plt.yticks(tick_marks, class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.tight_layout()
plt.show()

# ==== 9. Save Model ====
torch.save(model.state_dict(), "benthic_resnet50.pth")
print("âœ… Model saved as benthic_resnet50.pth")
